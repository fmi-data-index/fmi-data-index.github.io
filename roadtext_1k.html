<!DOCTYPE html>
<html>
    <head>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
        <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet"></link>
    </head>
    <body>
    <nav class="navbar navbar-dark bg-dark">
            <a class="navbar-brand" href="main.html">FMI Data Index</a>
            <button class="navbar-toggler collapsed" type="button" data-toggle="collapse" data-target="#navbarsExample01" aria-controls="navbarsExample01" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="navbar-collapse collapse" id="navbarsExample01" style="">
                <ul class="navbar-nav mr-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="cv_list.html">CV</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="nlp_list.html">NLP</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="audio_list.html">Audio</a>
                    </li>
                </ul>
            </div>
        </nav>
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
            integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
            crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"
            integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1"
            crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"
            integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
            crossorigin="anonymous"></script>       
        <div class='container' style="margin-top:2em;">
            <center><h1>RoadText-1K: Text Detection & Recognition Dataset for Driving Videos</h1></center>
            <center><a href="http://cvit.iiit.ac.in/research/projects/cvit-projects/roadtext-1k" target="_blank">http://cvit.iiit.ac.in/research/projects/cvit-projects/roadtext-1k</a></center>
        </div>
        <div class="container" style="margin-top:2em;">
            <div class="col" style="background:rgb(64, 147, 214);">
                <h2><font color='white'>Overview</font></h2>
            </div>
            <div class="col">
                <p>Perceiving text is crucial to understand semantics of outdoor scenes and hence is a critical requirement to build intelligent systems for driver assistance and self-driving. Most of the existing datasets for text detection and recognition comprise still images and are mostly compiled keeping text in mind. This paper introduces a new "RoadText-1K" dataset for text in driving videos. The dataset is 20 times larger than the existing largest dataset for text in videos. Our dataset comprises 1000 video clips of driving without any bias towards text and with annotations for text bounding boxes and transcriptions in every frame. State of the art methods for text detection, recognition and tracking are evaluated on the new dataset and the results signify the challenges in unconstrained driving videos compared to existing datasets. This suggests that RoadText-1K is suited for research and development of reading systems, robust enough to be incorporated into more complex downstream tasks like driver assistance and self-driving.</p>
            </div>
        </div>
        <div class="container" style="margin-top:2em;">
            <div class="col" style="background:rgb(64, 147, 214);">
                <h2><font color='white'>Associated Paper or Article</font></h2>
            </div>
            <div class="col">
                <p>For more information please read <a href="http://cdn.iiit.ac.in/cdn/cvit.iiit.ac.in/images/ConferencePapers/2020/RoadText-1K-ICRA_2020.pdf" target="_blank">RoadText-1K: Text Detection & Recognition Dataset for Driving Videos</a>.</p>    
            </div>
        </div>
        <div class="container" style="margin-top:2em;">
            <div class="col" style="background:rgb(64, 147, 214);">
                <h2><font color='white'>Annotations</font></h2>
            </div>
            <div class="col">
                <p>There are two types of annotation files, both in JSON format.</p>
                <p>The first type contain JSON arrays representing metadata about the images. Each element of those arrays contains an attribute specifying the presence of a road sign, another one specifying if the sign contains text and xy-coordinates of the box, as follows:</p>    
                <img src="./static/images/roadtext_1k_annotsample.png" height="600px">
                <p>The second type present JSON arrays that contain the ground-truth texts on the road signs inside the image. The elements' IDs match those in the previously presented annotation files. The text IDs match the bounging boxes IDs in the previously presented annotations.</p>
            </div>
        </div>
        <div class="container" style="margin-top:2em;">
            <div class="col" style="background:rgb(64, 147, 214);">
                <h2><font color='white'>Download</font></h2>
            </div>
            <div class="col">
                <p>The dataset can be downloaded <a href="https://iiitaphyd-my.sharepoint.com/personal/sangeeth_battu_research_iiit_ac_in/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fsangeeth%5Fbattu%5Fresearch%5Fiiit%5Fac%5Fin%2FDocuments%2FRoadText%2DDataset%2DIn%2DProgress%2FRoadText1k&originalPath=aHR0cHM6Ly9paWl0YXBoeWQtbXkuc2hhcmVwb2ludC5jb20vOmY6L2cvcGVyc29uYWwvc2FuZ2VldGhfYmF0dHVfcmVzZWFyY2hfaWlpdF9hY19pbi9FaGkzNjlKZDJHRkJwVURSUkFpRGhFSUJWZWF1S2JtUFllLVhsSkRyRmowMndRP3J0aW1lPXFyRnY1bzRhMkVn" target="_blank">here</a>.</p>
            </div>
        </div>
        <div class="container" style="margin-top:2em;">
            <div class="col" style="background:rgb(64, 147, 214);">
                <h2><font color='white'>Model</font></h2>
            </div>
            <div class="col">
                <p>No model has been provided for this dataset.</p>
            </div>
        </div>
        <div class="container" style="margin-top:2em;">
            <div class="col" style="background:rgb(64, 147, 214);">
                <h2><font color='white'>Benchmarks</font></h2>
            </div>
            <div class="col">
                <p>No benchmarks have been provided for this dataset.</p>
            </div>
        </div>
        <div class="container" style="margin-top:2em;">
            <div class="col" style="background:rgb(64, 147, 214);">
                <h2><font color='white'>Associated Challenges</font></h2>
            </div>
            <div class="col">
                <p>No associated challenges have been found for this dataset.</p>
           </div>
        </div>
        <div class="container" style="margin-top:2em;">
            <div class="col" style="background:rgb(64, 147, 214);">
                <h2><font color='white'>License</font></h2>
            </div>
            <div class="col">
                <p>Dataset licenced under the Non-Commercial licence.</p>
            </div>
        </div>
    </body>
</html>